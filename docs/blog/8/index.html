<!DOCTYPE html><html><head><title>jlam | TypeRacer scraper in Python</title><style>html {
	box-sizing: border-box;
	margin: 0;
	padding: 0.5rem;
}
body {
	max-width: 400pt;
	margin: 0 auto;
	padding: 0;
}</style><link rel="icon" href="/res/favicon.png"><meta name="viewport" content="width=device-width, initial-scale=1.0"></head><body><h1>Jonathan Lam</h1><p>EE/CS @ The Cooper Union</p><nav><a href="/">Home</a> | <a href="/contact">Contact</a> | <a href="/experience">Experience</a> | <a href="/res/resume.pdf" target="_blank">Resume</a> | <a href="http://files.lambdalambda.ninja">Files</a> | <a href="/blog">Blog</a></nav><hr><!-- inspiration taken from https://codepen.io/Zoxon/pen/WyqdBb--><h2>Blog</h2><h3>TypeRacer scraper in Python</h3><p>On 4/21/2021, 12:16:36 AM</p><p><a href="/blog">Return to blog</a></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js" integrity="sha512-YBk7HhgDZvBxmtOfUdvX0z8IH2d10Hp3aEygaMNhtF8fSOvBZ16D/1bXZTJV6ndk/L/DlXxYStP8jrF77v2MIg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-zc7WDnCM3aom2EziyDIRAtQg1mVXLdILE09Bo+aE1xk0AM2c2cVLfSW9NrxE5tKTX44WBY0Z2HClZ05ur9vB6A==" crossorigin="anonymous"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism-tomorrow.min.css" integrity="sha512-vswe+cgvic/XBoF1OcM/TeJ2FW0OofqAVdCZiEYkd6dwGXthvkSFWOoGGJgS2CW70VK5dQM5Oh+7ne47s74VTg==" crossorigin="anonymous"><style>pre {
	padding: .5rem !important;
	line-height: 1 !important;
}
code {
	line-height: 1 !important;
	font-size: 0.75rem !important;
	tab-size: 8 !important;
}
</style><p>I <a href="/blog/6">recently broke my record in TypeRacer</a>, so I thought I'd write a script to show my results over time. Here's it is.</p><p>This is actually my first time using a web scraper. BeautifulSoup is pretty nice.</p><p>The numerical running means and "running maxima" is not the most efficient, but it shouldn't be too bad with only a few thousand data points. The larger bottleneck is whether typeracerdata.com's server's can keep up for users with a large number of races.</p><p>As a stress test, I tried running the script on <a href="https://data.typeracer.com/pit/profile?user=keegant">keegant</a>, the user with the most TypeRacer races. Roughly speaking<sup id="footnote-1-indicator"><a href="#footnote-1">1</a></sup>, the HTML from typeracerdata.com took around 7 minutes and ate up 4.5GB of RAM, and the extra numpy arrays took up an extra 0.6GB and the processing (running mean and maxima) took about a second. See the output in the results section.</p><p>The end result definitely isn't perfect or complex, but it is pretty fun to see the progression over time. A possible improvement is that the horizontal axis is time rather than number of races (this would require parsing and storing the date values, which are also available on typeracerdata.com). The TypeRacer Discord server has a bot that allows you to view results as a function of either number of races or time, but (afaik) it doesn't give you control over the moving average or plot running maxima.</p><h4>Usage:</h4><pre><code class="language-bash">python3 scrape.py [USERNAME]
</code></pre><h4>Source:</h4><pre><code class="language-python">import matplotlib.pyplot as plt
import numpy as np
from datetime import date
from bs4 import BeautifulSoup
import requests
import sys

if len(sys.argv) < 2:
    print('Usage: python3 scrape.py [username]')
    
# max_races should be > total number of races
username = sys.argv[1]
max_races = 10000

# scrape from typeracerdata 
url = f'http://typeracerdata.com/profile?username={username}&last={max_races}'
page = requests.get(url)

soup = BeautifulSoup(page.content, 'html.parser')
data = np.array(list(map(lambda elem: float(elem.getText()), soup\
        .find_all('table', class_='profile')[2]\
        .select('td:nth-child(3)'))))

# reverse data
data = data[::-1]

# calculate average of N
averageofs = [10, 100, 1000]
def aveof(n):
    x = np.zeros(shape=(len(data)-n+1,))
    t = np.arange(n/2, n/2+len(data)-n+1)
    # set the zeroth element
    x[0] = np.sum(data[:n])
    # set the rest
    for i in range(1, len(data)-n+1):
        x[i] = x[i-1] + data[i+n-1] - data[i-1]
    x /= n
    return t, x

# calculate maximums
rolling_max = np.zeros_like(data)
curr_max = -1
for i, val in enumerate(data):
    if val > curr_max:
        curr_max = val
    rolling_max[i] = curr_max

# plot and save figure
plt.figure(figsize=[20, 10])
plt.plot(data)
for n in averageofs:
    plt.plot(*aveof(n))
plt.plot(rolling_max)
plt.grid('on')
plt.title(f'{username} Typeracer scores as of {date.today().strftime("%m/%d/%Y")}')
plt.xlabel('Race number')
plt.ylabel('Speed (wpm)')
plt.legend(['Raw'] + list(map(lambda x: f'Ao{x}', averageofs)) + ['Record'])
plt.tight_layout()
plt.xlim([0, len(data)])
plt.savefig(f'{username}{date.today().strftime("%d%m%Y")}.png')
</code></pre><h4>Output:</h4><p>Sample: my scores (username "jlam55555")</p><a href="/res/posts/6_history.png" target="_blank" title="click to open in new tab"><img src="/res/posts/6_history.png" alt="Sample outputted plot" style="max-width:100%;"></a><p>Sample: the creator of TypeRacer (username "typeracer")</p><a href="/res/posts/8_history_typeracer.png" target="_blank" title="click to open in new tab"><img src="/res/posts/8_history_typeracer.png" alt="Another sample outputted plot" style="max-width:100%;"></a><p>Sample: the user with the most races on TypeRacer (username "keegant")</p><a href="/res/posts/8_history_keegant.png" target="_blank" title="click to open in new tab"><img src="/res/posts/8_history_keegant.png" alt="Another sample outputted plot" style="max-width:100%;"></a><p id="footnote-1"><sup><a href="#footnote-1-indicator">1.</a> These estimates were performed by anxiously watching htop, hoping that I wouldn't run out of RAM</sup></p><hr><p>&copy; Copyright 2021 Jonathan Lam</p></body></html>